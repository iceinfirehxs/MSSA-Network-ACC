{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import  plot_model\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.io as sio\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft,fftshift\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    print('GPU acceleration is enabled')\n",
    "else:\n",
    "    print('GPU acceleration is not enabled')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSSA_Block(input,conv_kernel_sizes,filter_size,dropout_rate):\n",
    "    conv_attention_list=[]\n",
    "    for kernel_size in conv_kernel_sizes:\n",
    "        t_conv = keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size,padding=\"same\")(input)\n",
    "        t_conv = keras.layers.BatchNormalization()(t_conv)\n",
    "        # t_conv=keras.layers.Activation('tanh')(t_conv)\n",
    "        t_conv_attention=keras.layers.Attention()([t_conv,t_conv])\n",
    "        conv_attention_list.append(t_conv_attention)\n",
    "        pass\n",
    "\n",
    "    concat=K.concatenate(conv_attention_list)\n",
    "    concat=keras.layers.ReLU()(concat)\n",
    "    concat=keras.layers.Dropout(dropout_rate)(concat)\n",
    "    return concat\n",
    "\n",
    "\n",
    "def model_multiconv1d_attention(input_shape,blcok_num,conv_kernel_sizes,filter_size,dropout_rate):\n",
    "    input_layer = keras.layers.Input(shape=input_shape,name='input_layer')\n",
    "\n",
    "    concat=input_layer\n",
    "    for n in range(blcok_num):\n",
    "        concat=MSSA_Block(input=concat,conv_kernel_sizes=conv_kernel_sizes,filter_size=filter_size,dropout_rate=dropout_rate)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(concat)\n",
    "\n",
    "    output_layer = keras.layers.Dense(300, activation=\"linear\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_5fold=[]\n",
    "train_Y_5fold=[]\n",
    "valid_X_5fold=[]\n",
    "valid_Y_5fold=[]\n",
    "\n",
    "for n in range(5):\n",
    "    train_valid_dataset=sio.loadmat('./data/train_valid_data_'+str(n)+'_fold.mat')\n",
    "\n",
    "    train_X=train_valid_dataset['train_data_X']\n",
    "    train_Y=train_valid_dataset['train_data_Y']\n",
    "\n",
    "    train_X_5fold.append(train_X)\n",
    "    train_Y_5fold.append(train_Y)\n",
    "\n",
    "    valid_X=train_valid_dataset['valid_data_X']\n",
    "    valid_Y=train_valid_dataset['valid_data_Y']\n",
    "\n",
    "    valid_X_5fold.append(valid_X)\n",
    "    valid_Y_5fold.append(valid_Y)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weighted mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=5\n",
    "def weighted_mse(y_true, y_pred):\n",
    "    mse_square = K.square(y_pred - y_true)\n",
    "\n",
    "    condition = K.greater(y_true, 0)\n",
    "    mse_square_adjusted = K.switch(condition, alpha * mse_square, mse_square)\n",
    "\n",
    "    mse = K.mean(mse_square_adjusted)\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model 5 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "epochs=550\n",
    "\n",
    "adam=keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "\n",
    "blcok_num=4\n",
    "conv_kernel_sizes=[3,7,15]\n",
    "filter_size=32\n",
    "dropout_rate=0.2\n",
    "\n",
    "for n in range(5):\n",
    "    print('train no.'+str(n)+' fold model')\n",
    "\n",
    "    train_X=train_X_5fold[n]\n",
    "    train_Y=train_Y_5fold[n]\n",
    "\n",
    "    valid_X=valid_X_5fold[n]\n",
    "    valid_Y=valid_Y_5fold[n]\n",
    "\n",
    "\n",
    "    train_X_input=train_X.reshape((train_X.shape[0],train_X.shape[1],1))\n",
    "    valid_X_input=valid_X.reshape((valid_X.shape[0],valid_X.shape[1],1))\n",
    "\n",
    "    # ............................................................................................\n",
    "    model=model_multiconv1d_attention(train_X_input.shape[1:],blcok_num=blcok_num,conv_kernel_sizes=conv_kernel_sizes,filter_size=filter_size,dropout_rate=dropout_rate)\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        # loss='mean_squared_error',\n",
    "        loss=weighted_mse,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_X_input,\n",
    "        train_Y,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(valid_X_input,valid_Y),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # ............................................................................................\n",
    "    modle_name=\"model_multiconv1d_attention\"+'_'+str(n)+'_fold'\n",
    "    model.save(modle_name+'.h5') \n",
    "\n",
    "    plt.figure()  \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.ylabel(\"loss\", fontsize=\"large\")\n",
    "    plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "    plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "    plt.savefig(modle_name+'_loss.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2265b7fa597584c0ffc6a76b10e87b2b2e79bdf43e7cf271b07ac486fe92a8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
